{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3d5800b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import math\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torch\n",
    "from torchvision.transforms import functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_sched\n",
    "\n",
    "from vit import ViTBackbone, ViTWithExtraFeatures, ClassificationHead\n",
    "from feature_extractors import LBPExtractor, HOGExtractor, SIFTExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d1dccb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"configs.yaml\", \"r\", encoding=\"utf-8\") as f:\n",
    "    cfg = yaml.safe_load(f)\n",
    "\n",
    "cfg_model = cfg['model']\n",
    "cfg_train = cfg['training']\n",
    "\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb9d127",
   "metadata": {},
   "source": [
    "### Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "aae4b4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'data'\n",
    "batch_size = cfg_train[\"batch_size\"]\n",
    "num_workers = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b2d83e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_mean = [0.5524, 0.5288, 0.5107]\n",
    "channel_std  = [0.0956, 0.0773, 0.0465]\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=channel_mean, std=channel_std)\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=channel_mean, std=channel_std)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6c5ce36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset = datasets.ImageFolder(\n",
    "    root=data_path, transform=train_transform\n",
    ")\n",
    "\n",
    "total_size = len(full_dataset)\n",
    "train_size = int(0.025 * total_size)\n",
    "test_size  = total_size - train_size\n",
    "\n",
    "train_dataset, test_dataset = random_split(\n",
    "    full_dataset, [train_size, test_size],\n",
    "    generator=torch.Generator().manual_seed(42)\n",
    ")\n",
    "test_dataset.dataset.transform = test_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "155c59c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=batch_size, \n",
    "    shuffle=True,  num_workers=num_workers\n",
    ")\n",
    "test_loader  = DataLoader(\n",
    "    test_dataset,  batch_size=batch_size,\n",
    "    shuffle=False, num_workers=num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27580066",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "94c4f542",
   "metadata": {},
   "outputs": [],
   "source": [
    "vit_backbone = ViTBackbone(\n",
    "    in_channels=cfg_model[\"vit\"][\"in_channels\"],\n",
    "    embedding_dim=cfg_model[\"vit\"][\"embedding_dim\"],\n",
    "    patch_size=cfg_model[\"vit\"][\"patch_size\"],\n",
    "    max_patch_num=cfg_model[\"vit\"][\"max_patch_num\"],\n",
    "    L=cfg_model[\"vit\"][\"depth\"],\n",
    "    n_heads=cfg_model[\"vit\"][\"n_heads\"],\n",
    "    mlp_size=cfg_model[\"vit\"][\"mlp_size\"]\n",
    ")\n",
    "extractors = nn.ModuleList([\n",
    "    LBPExtractor(),\n",
    "    HOGExtractor(),\n",
    "    SIFTExtractor()\n",
    "])\n",
    "\n",
    "model = ViTWithExtraFeatures(\n",
    "    vit_backbone=vit_backbone,\n",
    "    feature_extractors=extractors,\n",
    "    n_classes=cfg_model[\"cls\"][\"n_classes\"]\n",
    ")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1af66b",
   "metadata": {},
   "source": [
    "### Train (with Feature Engineering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d85f4d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lr_lambda(num_epochs, warmup_epochs):\n",
    "    def lr_lambda(epoch):\n",
    "        if epoch < warmup_epochs:\n",
    "            return (epoch + 1) / warmup_epochs\n",
    "        else:\n",
    "            progress = (epoch - warmup_epochs) / (num_epochs - warmup_epochs)\n",
    "            return 0.5 * (1.0 + math.cos(math.pi * progress))\n",
    "    \n",
    "    return lr_lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "10e19537",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(\n",
    "    model.parameters(), \n",
    "    lr=float(cfg_train[\"lr\"])\n",
    ")\n",
    "scheduler = lr_sched.LambdaLR(\n",
    "    optimizer, \n",
    "    lr_lambda=get_lr_lambda(\n",
    "        num_epochs=cfg_train[\"num_epochs\"],\n",
    "        warmup_epochs=cfg_train[\"warmup_epochs\"]\n",
    "    )\n",
    ")\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c4668148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30], Loss: 1.5276, Test Accuracy: 49.40%\n",
      "Epoch [2/30], Loss: 1.3962, Test Accuracy: 65.86%\n",
      "Epoch [3/30], Loss: 1.3164, Test Accuracy: 66.42%\n",
      "Epoch [4/30], Loss: 1.3401, Test Accuracy: 50.88%\n",
      "Epoch [5/30], Loss: 1.3325, Test Accuracy: 51.58%\n",
      "Epoch [6/30], Loss: 1.2917, Test Accuracy: 59.82%\n",
      "Epoch [7/30], Loss: 1.2509, Test Accuracy: 65.61%\n",
      "Epoch [8/30], Loss: 1.2485, Test Accuracy: 65.02%\n",
      "Epoch [9/30], Loss: 1.2294, Test Accuracy: 62.62%\n",
      "Epoch [10/30], Loss: 1.1839, Test Accuracy: 60.96%\n",
      "Epoch [11/30], Loss: 1.1413, Test Accuracy: 62.28%\n",
      "Epoch [12/30], Loss: 1.1064, Test Accuracy: 64.91%\n",
      "Epoch [13/30], Loss: 1.0767, Test Accuracy: 67.15%\n",
      "Epoch [14/30], Loss: 1.0509, Test Accuracy: 67.66%\n",
      "Epoch [15/30], Loss: 1.0246, Test Accuracy: 67.54%\n",
      "Epoch [16/30], Loss: 0.9950, Test Accuracy: 67.21%\n",
      "Epoch [17/30], Loss: 0.9685, Test Accuracy: 66.34%\n",
      "Epoch [18/30], Loss: 0.9493, Test Accuracy: 66.06%\n",
      "Epoch [19/30], Loss: 0.9358, Test Accuracy: 66.31%\n",
      "Epoch [20/30], Loss: 0.9252, Test Accuracy: 66.87%\n",
      "Epoch [21/30], Loss: 0.9163, Test Accuracy: 67.43%\n",
      "Epoch [22/30], Loss: 0.9081, Test Accuracy: 67.57%\n",
      "Epoch [23/30], Loss: 0.9012, Test Accuracy: 67.66%\n",
      "Epoch [24/30], Loss: 0.8944, Test Accuracy: 67.74%\n",
      "Epoch [25/30], Loss: 0.8893, Test Accuracy: 67.71%\n",
      "Epoch [26/30], Loss: 0.8850, Test Accuracy: 67.68%\n",
      "Epoch [27/30], Loss: 0.8820, Test Accuracy: 67.63%\n",
      "Epoch [28/30], Loss: 0.8799, Test Accuracy: 67.57%\n",
      "Epoch [29/30], Loss: 0.8786, Test Accuracy: 67.57%\n",
      "Epoch [30/30], Loss: 0.8784, Test Accuracy: 67.57%\n",
      "Training finished.\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(cfg_train[\"num_epochs\"]):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for batch_idx, (images, labels) in enumerate(train_loader, 1):\n",
    "        print(f\"\\rProcessed {batch_idx}/{len(train_loader)} batches\", end='')\n",
    "\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    scheduler.step()\n",
    "\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "\n",
    "            _, predicted = torch.max(outputs, dim=1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100.0 * correct / total\n",
    "    print(\n",
    "        f\"\\rEpoch [{epoch+1}/{cfg_train['num_epochs']}], \"\n",
    "        f\"Loss: {avg_loss:.4f}, Test Accuracy: {accuracy:.2f}%\"\n",
    "    )\n",
    "\n",
    "print(\"Training finished.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genenv1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
