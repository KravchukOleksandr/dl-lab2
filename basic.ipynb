{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d5800b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import math\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torch\n",
    "from torchvision.transforms import functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.amp import autocast, GradScaler\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_sched\n",
    "\n",
    "from vit import ViTBackbone, ClassificationHead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d1dccb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"configs.yaml\", \"r\", encoding=\"utf-8\") as f:\n",
    "    cfg = yaml.safe_load(f)\n",
    "\n",
    "cfg_model = cfg['model']\n",
    "cfg_train = cfg['training']\n",
    "\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb9d127",
   "metadata": {},
   "source": [
    "### Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aae4b4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'data'\n",
    "batch_size = cfg_train[\"batch_size\"]\n",
    "num_workers = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b2d83e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_mean = [0.5524, 0.5288, 0.5107]\n",
    "channel_std  = [0.0956, 0.0773, 0.0465]\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=channel_mean, std=channel_std)\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=channel_mean, std=channel_std)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6c5ce36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset = datasets.ImageFolder(\n",
    "    root=data_path, transform=train_transform\n",
    ")\n",
    "\n",
    "total_size = len(full_dataset)\n",
    "train_size = int(0.025 * total_size)\n",
    "test_size  = total_size - train_size\n",
    "\n",
    "train_dataset, test_dataset = random_split(\n",
    "    full_dataset, [train_size, test_size],\n",
    "    generator=torch.Generator().manual_seed(42)\n",
    ")\n",
    "test_dataset.dataset.transform = test_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "155c59c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=batch_size, \n",
    "    shuffle=True,  num_workers=num_workers\n",
    ")\n",
    "test_loader  = DataLoader(\n",
    "    test_dataset,  batch_size=batch_size,\n",
    "    shuffle=False, num_workers=num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27580066",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "94c4f542",
   "metadata": {},
   "outputs": [],
   "source": [
    "vit_backbone = ViTBackbone(\n",
    "    in_channels=cfg_model[\"vit\"][\"in_channels\"],\n",
    "    embedding_dim=cfg_model[\"vit\"][\"embedding_dim\"],\n",
    "    patch_size=cfg_model[\"vit\"][\"patch_size\"],\n",
    "    max_patch_num=cfg_model[\"vit\"][\"max_patch_num\"],\n",
    "    L=cfg_model[\"vit\"][\"depth\"],\n",
    "    n_heads=cfg_model[\"vit\"][\"n_heads\"],\n",
    "    mlp_size=cfg_model[\"vit\"][\"mlp_size\"]\n",
    ")\n",
    "classifier = ClassificationHead(\n",
    "    embedding_dim=cfg_model[\"vit\"][\"embedding_dim\"],\n",
    "    n_classes=cfg_model[\"cls\"][\"n_classes\"]\n",
    ")\n",
    "\n",
    "model = nn.Sequential(\n",
    "    vit_backbone,\n",
    "    classifier\n",
    ")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1af66b",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d85f4d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lr_lambda(num_epochs, warmup_epochs):\n",
    "    def lr_lambda(epoch):\n",
    "        if epoch < warmup_epochs:\n",
    "            return (epoch + 1) / warmup_epochs\n",
    "        else:\n",
    "            progress = (epoch - warmup_epochs) / (num_epochs - warmup_epochs)\n",
    "            return 0.5 * (1.0 + math.cos(math.pi * progress))\n",
    "    \n",
    "    return lr_lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "10e19537",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(\n",
    "    model.parameters(), \n",
    "    lr=float(cfg_train[\"lr\"])\n",
    ")\n",
    "scheduler = lr_sched.LambdaLR(\n",
    "    optimizer, \n",
    "    lr_lambda=get_lr_lambda(\n",
    "        num_epochs=cfg_train[\"num_epochs\"],\n",
    "        warmup_epochs=cfg_train[\"warmup_epochs\"]\n",
    "    )\n",
    ")\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c4668148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30], Loss: 2.1423, Test Accuracy: 27.25%\n",
      "Epoch [2/30], Loss: 1.8544, Test Accuracy: 24.11%\n",
      "Epoch [3/30], Loss: 1.4771, Test Accuracy: 49.40%\n",
      "Epoch [4/30], Loss: 1.5881, Test Accuracy: 49.40%\n",
      "Epoch [5/30], Loss: 1.7310, Test Accuracy: 49.40%\n",
      "Epoch [6/30], Loss: 1.6052, Test Accuracy: 49.40%\n",
      "Epoch [7/30], Loss: 1.4178, Test Accuracy: 49.37%\n",
      "Epoch [8/30], Loss: 1.3798, Test Accuracy: 27.47%\n",
      "Epoch [9/30], Loss: 1.4393, Test Accuracy: 27.47%\n",
      "Epoch [10/30], Loss: 1.4416, Test Accuracy: 29.43%\n",
      "Epoch [11/30], Loss: 1.3932, Test Accuracy: 58.11%\n",
      "Epoch [12/30], Loss: 1.3392, Test Accuracy: 54.47%\n",
      "Epoch [13/30], Loss: 1.3002, Test Accuracy: 49.82%\n",
      "Epoch [14/30], Loss: 1.2788, Test Accuracy: 49.43%\n",
      "Epoch [15/30], Loss: 1.2668, Test Accuracy: 49.40%\n",
      "Epoch [16/30], Loss: 1.2542, Test Accuracy: 49.40%\n",
      "Epoch [17/30], Loss: 1.2357, Test Accuracy: 49.45%\n",
      "Epoch [18/30], Loss: 1.2123, Test Accuracy: 50.13%\n",
      "Epoch [19/30], Loss: 1.1885, Test Accuracy: 53.32%\n",
      "Epoch [20/30], Loss: 1.1686, Test Accuracy: 57.46%\n",
      "Epoch [21/30], Loss: 1.1543, Test Accuracy: 61.10%\n",
      "Epoch [22/30], Loss: 1.1449, Test Accuracy: 63.32%\n",
      "Epoch [23/30], Loss: 1.1385, Test Accuracy: 64.18%\n",
      "Epoch [24/30], Loss: 1.1338, Test Accuracy: 64.46%\n",
      "Epoch [25/30], Loss: 1.1299, Test Accuracy: 64.58%\n",
      "Epoch [26/30], Loss: 1.1266, Test Accuracy: 64.66%\n",
      "Epoch [27/30], Loss: 1.1240, Test Accuracy: 64.63%\n",
      "Epoch [28/30], Loss: 1.1221, Test Accuracy: 64.66%\n",
      "Epoch [29/30], Loss: 1.1209, Test Accuracy: 64.66%\n",
      "Epoch [30/30], Loss: 1.1204, Test Accuracy: 64.63%\n",
      "Training finished.\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(cfg_train[\"num_epochs\"]):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for batch_idx, (images, labels) in enumerate(train_loader, 1):\n",
    "        print(f\"\\rProcessed {batch_idx}/{len(train_loader)} batches\", end='')\n",
    "\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    scheduler.step()\n",
    "\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "\n",
    "            _, predicted = torch.max(outputs, dim=1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100.0 * correct / total\n",
    "    print(\n",
    "        f\"\\rEpoch [{epoch+1}/{cfg_train['num_epochs']}], \"\n",
    "        f\"Loss: {avg_loss:.4f}, Test Accuracy: {accuracy:.2f}%\"\n",
    "    )\n",
    "\n",
    "print(\"Training finished.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genenv1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
